{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "from pathlib import Path\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, RandomSampler, Subset\n",
    "from torchvision import transforms\n",
    "from torch.nn import MSELoss\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "from lfxai.models.images import AutoEncoderMnist, EncoderMnist, DecoderMnist\n",
    "from lfxai.models.pretext import Identity, RandomNoise\n",
    "from lfxai.explanations.features import attribute_auxiliary\n",
    "from lfxai.explanations.examples import SimplEx, InfluenceFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoderMnist(\n",
       "  (encoder): EncoderMnist(\n",
       "    (encoder_cnn): Sequential(\n",
       "      (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (6): ReLU(inplace=True)\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (encoder_lin): Sequential(\n",
       "      (0): Linear(in_features=288, out_features=128, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=128, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): DecoderMnist(\n",
       "    (decoder_lin): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=128, out_features=288, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (unflatten): Unflatten(dim=1, unflattened_size=(32, 3, 3))\n",
       "    (decoder_conv): Sequential(\n",
       "      (0): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): ConvTranspose2d(8, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (loss_f): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed: int = 1\n",
    "batch_size: int = 200\n",
    "dim_latent: int = 4\n",
    "n_epochs: int = 100\n",
    "subtrain_size: int = 1000\n",
    "\n",
    "# Initialize seed and device\n",
    "torch.random.manual_seed(random_seed)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Load MNIST\n",
    "data_dir = Path.cwd() / \"data/mnist\"\n",
    "train_dataset = torchvision.datasets.MNIST(data_dir, train=True, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n",
    "train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset.transform = train_transform\n",
    "test_dataset.transform = test_transform\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "# Initialize encoder, decoder and autoencoder wrapper\n",
    "pert = RandomNoise()\n",
    "encoder = EncoderMnist(encoded_space_dim=dim_latent)\n",
    "decoder = DecoderMnist(encoded_space_dim=dim_latent)\n",
    "autoencoder = AutoEncoderMnist(encoder, decoder, dim_latent, pert)\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "autoencoder.to(device)\n",
    "\n",
    "# Train the denoising autoencoder\n",
    "save_dir = Path.cwd() / \"results/mnist/consistency_examples\"\n",
    "if not save_dir.exists():\n",
    "    os.makedirs(save_dir)\n",
    "if not (save_dir / (autoencoder.name + \".pt\")).exists():\n",
    "    autoencoder.fit(\n",
    "        device, train_loader, test_loader, save_dir, n_epochs, checkpoint_interval=10\n",
    "    )\n",
    "else:      \n",
    "    autoencoder.load_state_dict(\n",
    "        torch.load(save_dir / (autoencoder.name + \".pt\")), strict=False\n",
    "    )\n",
    "autoencoder.train().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m results_dict \u001b[39m=\u001b[39m {}\n\u001b[0;32m     36\u001b[0m \u001b[39mfor\u001b[39;00m explainer \u001b[39min\u001b[39;00m explainer_list:\n\u001b[1;32m---> 37\u001b[0m     attribution \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39;49mattribute_loader(\n\u001b[0;32m     38\u001b[0m         device,\n\u001b[0;32m     39\u001b[0m         subtrain_loader,\n\u001b[0;32m     40\u001b[0m         subtest_loader,\n\u001b[0;32m     41\u001b[0m         train_loader_replacement\u001b[39m=\u001b[39;49mtrain_loader_replacement,\n\u001b[0;32m     42\u001b[0m         recursion_depth\u001b[39m=\u001b[39;49mrecursion_depth,\n\u001b[0;32m     43\u001b[0m     )\n\u001b[0;32m     44\u001b[0m     autoencoder\u001b[39m.\u001b[39mload_state_dict(\n\u001b[0;32m     45\u001b[0m         torch\u001b[39m.\u001b[39mload(save_dir \u001b[39m/\u001b[39m (autoencoder\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m)), strict\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     )\n\u001b[0;32m     47\u001b[0m     results_dict[\u001b[39mstr\u001b[39m(explainer)] \u001b[39m=\u001b[39m attribution\n",
      "File \u001b[1;32mc:\\Users\\albac\\anaconda3\\envs\\minitaskVDSLab\\lib\\site-packages\\lfxai\\explanations\\examples.py:191\u001b[0m, in \u001b[0;36mInfluenceFunctions.attribute_loader\u001b[1;34m(self, device, train_loader, test_loader, train_loader_replacement, recursion_depth, damp, scale, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m     sampled_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_f(X_sample, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(X_sample))\n\u001b[0;32m    189\u001b[0m     ihvp_prev \u001b[39m=\u001b[39m ihvp\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mclone()\n\u001b[0;32m    190\u001b[0m     hvp \u001b[39m=\u001b[39m stack_torch_tensors(\n\u001b[1;32m--> 191\u001b[0m         hessian_vector_product(sampled_loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, ihvp_prev)\n\u001b[0;32m    192\u001b[0m     )\n\u001b[0;32m    193\u001b[0m     ihvp \u001b[39m=\u001b[39m grad \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m damp) \u001b[39m*\u001b[39m ihvp \u001b[39m-\u001b[39m hvp \u001b[39m/\u001b[39m scale\n\u001b[0;32m    194\u001b[0m ihvp \u001b[39m=\u001b[39m ihvp \u001b[39m/\u001b[39m (scale \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(train_loader))  \u001b[39m# Rescale Hessian-Vector products\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\albac\\anaconda3\\envs\\minitaskVDSLab\\lib\\site-packages\\lfxai\\utils\\influence.py:61\u001b[0m, in \u001b[0;36mhessian_vector_product\u001b[1;34m(loss, model, v)\u001b[0m\n\u001b[0;32m     58\u001b[0m elemwise_products \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdot(first_grads\u001b[39m.\u001b[39mflatten(), v\u001b[39m.\u001b[39mflatten())\n\u001b[0;32m     60\u001b[0m \u001b[39m# Second backprop\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m HVP_ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mgrad(elemwise_products, model\u001b[39m.\u001b[39;49mencoder\u001b[39m.\u001b[39;49mparameters())\n\u001b[0;32m     63\u001b[0m \u001b[39mreturn\u001b[39;00m HVP_\n",
      "File \u001b[1;32mc:\\Users\\albac\\anaconda3\\envs\\minitaskVDSLab\\lib\\site-packages\\torch\\autograd\\__init__.py:394\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[0;32m    390\u001b[0m     result \u001b[39m=\u001b[39m _vmap_internals\u001b[39m.\u001b[39m_vmap(vjp, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, allow_none_pass_through\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(\n\u001b[0;32m    391\u001b[0m         grad_outputs_\n\u001b[0;32m    392\u001b[0m     )\n\u001b[0;32m    393\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 394\u001b[0m     result \u001b[39m=\u001b[39m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    395\u001b[0m         t_outputs,\n\u001b[0;32m    396\u001b[0m         grad_outputs_,\n\u001b[0;32m    397\u001b[0m         retain_graph,\n\u001b[0;32m    398\u001b[0m         create_graph,\n\u001b[0;32m    399\u001b[0m         t_inputs,\n\u001b[0;32m    400\u001b[0m         allow_unused,\n\u001b[0;32m    401\u001b[0m         accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    402\u001b[0m     )  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[39mif\u001b[39;00m materialize_grads:\n\u001b[0;32m    404\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\n\u001b[0;32m    405\u001b[0m         output\n\u001b[0;32m    406\u001b[0m         \u001b[39mif\u001b[39;00m output \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    407\u001b[0m         \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mzeros_like(\u001b[39minput\u001b[39m, requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    408\u001b[0m         \u001b[39mfor\u001b[39;00m (output, \u001b[39minput\u001b[39m) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(result, t_inputs)\n\u001b[0;32m    409\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "idx_subtrain = [\n",
    "    torch.nonzero(train_dataset.targets == (n % 10))[n // 10].item()\n",
    "    for n in range(subtrain_size)\n",
    "]\n",
    "\n",
    "idx_subtest = [\n",
    "    torch.nonzero(test_dataset.targets == (n % 10))[n // 10].item()\n",
    "    for n in range(subtrain_size)\n",
    "]\n",
    "\n",
    "train_subset = Subset(train_dataset, idx_subtrain)\n",
    "test_subset = Subset(test_dataset, idx_subtest)\n",
    "subtrain_loader = DataLoader(train_subset)\n",
    "subtest_loader = DataLoader(test_subset)\n",
    "labels_subtrain = torch.cat([label for _, label in subtrain_loader])\n",
    "labels_subtest = torch.cat([label for _, label in subtest_loader])\n",
    "\n",
    "# Create a training set sampler with replacement for computing influence functions\n",
    "recursion_depth = 100\n",
    "train_sampler = RandomSampler(\n",
    "    train_dataset, replacement=True, num_samples=recursion_depth * batch_size\n",
    ")\n",
    "train_loader_replacement = DataLoader(\n",
    "    train_dataset, batch_size, sampler=train_sampler\n",
    ")\n",
    "\n",
    "# Fitting explainers, computing the metric and saving everything\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "explainer_list = [\n",
    "    InfluenceFunctions(autoencoder, mse_loss, save_dir / \"if_grads\"),\n",
    "]\n",
    "\n",
    "frac_list = [0.05, 0.1, 0.2, 0.5, 0.7, 1.0]\n",
    "n_top_list = [int(frac * len(idx_subtrain)) for frac in frac_list]\n",
    "results_dict = {}\n",
    "for explainer in explainer_list:\n",
    "    attribution = explainer.attribute_loader(\n",
    "        device,\n",
    "        subtrain_loader,\n",
    "        subtest_loader,\n",
    "        train_loader_replacement=train_loader_replacement,\n",
    "        recursion_depth=recursion_depth,\n",
    "    )\n",
    "    autoencoder.load_state_dict(\n",
    "        torch.load(save_dir / (autoencoder.name + \".pt\")), strict=False\n",
    "    )\n",
    "    results_dict[str(explainer)] = attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_subtrain = [\n",
    "    torch.nonzero(train_dataset.targets == (n % 10))[n // 10].item()\n",
    "    for n in range(subtrain_size)\n",
    "]\n",
    "\n",
    "idx_subtest = [\n",
    "    torch.nonzero(test_dataset.targets == (n % 10))[n // 10].item()\n",
    "    for n in range(subtrain_size)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: c:\\Users\\albac\\Desktop\\PostGrad\\Cambridge\\minitaskVDSLab\\data\\mnist\n",
       "    Split: Test"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_subtrain), len(idx_subtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_subtrain = [\n",
    "    torch.nonzero(train_dataset.targets == (n % 10))[n // 10].item()\n",
    "    for n in range(subtrain_size)\n",
    "]\n",
    "\n",
    "idx_subtest = [\n",
    "    torch.nonzero(test_dataset.targets == (n % 10))[n // 10].item()\n",
    "    for n in range(subtrain_size)\n",
    "]\n",
    "\n",
    "train_subset = Subset(train_dataset, idx_subtrain)\n",
    "test_subset = Subset(test_dataset, idx_subtest)\n",
    "subtrain_loader = DataLoader(train_subset)\n",
    "subtest_loader = DataLoader(test_subset)\n",
    "labels_subtrain = torch.cat([label for _, label in subtrain_loader])\n",
    "labels_subtest = torch.cat([label for _, label in subtest_loader])\n",
    "\n",
    "# Create a training set sampler with replacement for computing influence functions\n",
    "recursion_depth = 100\n",
    "train_sampler = RandomSampler(\n",
    "    train_dataset, replacement=True, num_samples=recursion_depth * batch_size\n",
    ")\n",
    "train_loader_replacement = DataLoader(\n",
    "    train_dataset, batch_size, sampler=train_sampler\n",
    ")\n",
    "\n",
    "# Fitting explainers, computing the metric and saving everything\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "explainer_list = [\n",
    "    InfluenceFunctions(autoencoder, mse_loss, save_dir / \"if_grads\"),\n",
    "]\n",
    "\n",
    "frac_list = [0.05, 0.1, 0.2, 0.5, 0.7, 1.0]\n",
    "n_top_list = [int(frac * len(idx_subtrain)) for frac in frac_list]\n",
    "results_dict = {}\n",
    "for explainer in explainer_list:\n",
    "    attribution = explainer.attribute_loader(\n",
    "        device,\n",
    "        subtrain_loader,\n",
    "        subtest_loader,\n",
    "        train_loader_replacement=train_loader_replacement,\n",
    "        recursion_depth=recursion_depth,\n",
    "    )\n",
    "    autoencoder.load_state_dict(\n",
    "        torch.load(save_dir / (autoencoder.name + \".pt\")), strict=False\n",
    "    )\n",
    "    results_dict[str(explainer)] = attribution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minitaskVDSLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
